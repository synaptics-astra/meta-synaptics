From a0d9bda86db3664ed5038155f7d80edb637d8709 Mon Sep 17 00:00:00 2001
From: Xiaomei Shang <xiaomei.shang@synaptics.com>
Date: Fri, 1 Mar 2024 17:38:23 +0800
Subject: [PATCH] fix: unimplementated functions

---
 .../4bit/fully_connected_reference.h          | 38 +++++++++----------
 1 file changed, 19 insertions(+), 19 deletions(-)

diff --git a/tensorflow/lite/kernels/internal/optimized/4bit/fully_connected_reference.h b/tensorflow/lite/kernels/internal/optimized/4bit/fully_connected_reference.h
index b44f89996df..af144e86673 100644
--- a/tensorflow/lite/kernels/internal/optimized/4bit/fully_connected_reference.h
+++ b/tensorflow/lite/kernels/internal/optimized/4bit/fully_connected_reference.h
@@ -53,8 +53,8 @@ inline void PackInner(const int8_t* src, uint8_t* box, int src_rows,
 inline void Prepack(uint8_t* dest, const int8_t* tensor, int layout_rows,
                     int layout_cols, int src_rows, int src_cols, int width,
                     int depth) {
-  ReferencePrepack(dest, tensor, layout_rows, layout_cols, src_rows, src_cols,
-                   width, depth);
+//   ReferencePrepack(dest, tensor, layout_rows, layout_cols, src_rows, src_cols,
+//                    width, depth);
 }
 
 /* Quantize input floats to 8bit and calculate sum of each column.
@@ -67,9 +67,9 @@ inline void BatchQuantizeFloats4Bit(const float* float_data_ptr, int n_batch,
                                     int n_data, int8_t* quantized_data_ptr,
                                     float* scaling_factors, int width,
                                     int depth, int32_t* input_offsets) {
-  ReferenceBatchQuantizeFloats4Bit(float_data_ptr, n_batch, n_data,
-                                   quantized_data_ptr, scaling_factors, width,
-                                   depth, input_offsets);
+//   ReferenceBatchQuantizeFloats4Bit(float_data_ptr, n_batch, n_data,
+//                                    quantized_data_ptr, scaling_factors, width,
+//                                    depth, input_offsets);
 }
 
 /* Write bias + input offset * filter_scale to output_ptr.
@@ -83,9 +83,9 @@ inline void AssignBiasAndComputeOffsets(const int32_t* input_offsets,
                                         const float* bias_ptr,
                                         float* output_ptr, int output_depth,
                                         int batch_size) {
-  ReferenceAssignBiasAndComputeOffsets(input_offsets, batch_scales,
-                                       filter_scales, bias_ptr, output_ptr,
-                                       output_depth, batch_size);
+//   ReferenceAssignBiasAndComputeOffsets(input_offsets, batch_scales,
+//                                        filter_scales, bias_ptr, output_ptr,
+//                                        output_depth, batch_size);
 }
 
 /* Add accumulated integer sums in dst to float output.
@@ -124,8 +124,8 @@ inline void Unpack<4, 1>(float* output_ptr, const int32_t* dst, int batch_size,
                          int num_units, const float* scaling_factors,
                          const float* filter_scales, int dst_layout_rows,
                          int dst_layout_cols) {
-  ReferenceUnpack<4, 1>(output_ptr, dst, batch_size, num_units, scaling_factors,
-                        filter_scales, dst_layout_rows, dst_layout_cols);
+//   ReferenceUnpack<4, 1>(output_ptr, dst, batch_size, num_units, scaling_factors,
+//                         filter_scales, dst_layout_rows, dst_layout_cols);
 }
 
 template <>
@@ -134,9 +134,9 @@ inline void RunKernel<4, 1, 32>(const uint8_t* lhs, const int8_t* rhs,
                                 int lhs_layout_cols, int rhs_layout_rows,
                                 int rhs_layout_cols, int dst_layout_rows,
                                 int dst_layout_cols) {
-  ReferenceRunKernel<4, 1, 32>(lhs, rhs, dst, lhs_layout_rows, lhs_layout_cols,
-                               rhs_layout_rows, rhs_layout_cols,
-                               dst_layout_rows, dst_layout_cols);
+//   ReferenceRunKernel<4, 1, 32>(lhs, rhs, dst, lhs_layout_rows, lhs_layout_cols,
+//                                rhs_layout_rows, rhs_layout_cols,
+//                                dst_layout_rows, dst_layout_cols);
 }
 
 // End template specializations.
@@ -149,12 +149,12 @@ inline void RunAndUnpack(int rhs_width, const uint8_t* lhs, const int8_t* rhs,
                          int dst_layout_rows, int dst_layout_cols,
                          float* output_ptr, const float* scaling_factors,
                          const float* filter_scales) {
-  ReferenceRunKernel<4, 1, 32>(lhs, rhs, dst, lhs_layout_rows, lhs_layout_cols,
-                               rhs_layout_rows, rhs_layout_cols,
-                               dst_layout_rows, dst_layout_cols);
-  ReferenceUnpack<4, 1>(output_ptr, dst, batch_size, output_depth,
-                        scaling_factors, filter_scales, dst_layout_rows,
-                        dst_layout_cols);
+//   ReferenceRunKernel<4, 1, 32>(lhs, rhs, dst, lhs_layout_rows, lhs_layout_cols,
+//                                rhs_layout_rows, rhs_layout_cols,
+//                                dst_layout_rows, dst_layout_cols);
+//   ReferenceUnpack<4, 1>(output_ptr, dst, batch_size, output_depth,
+//                         scaling_factors, filter_scales, dst_layout_rows,
+//                         dst_layout_cols);
 }
 
 }  // namespace optimized_4bit
-- 
2.17.1

